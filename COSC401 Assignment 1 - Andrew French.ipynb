{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  name                                              value\n",
      "0   X1  LinearRegression(copy_X=True, fit_intercept=Tr...\n",
      "1   X2  LinearRegression(copy_X=True, fit_intercept=Tr...\n",
      "2   X3  LinearRegression(copy_X=True, fit_intercept=Tr...\n",
      "3    A  LinearRegression(copy_X=True, fit_intercept=Tr...\n",
      "4    B  LinearRegression(copy_X=True, fit_intercept=Tr...\n",
      "5    C  LinearRegression(copy_X=True, fit_intercept=Tr...\n",
      "Mean squared error: 51.178608246662264\n",
      "R²: 0.6554272705683302\n"
     ]
    }
   ],
   "source": [
    "# Part 1\n",
    "# Andrew French - 11147452\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, train_test_split, cross_val_score\n",
    "from sklearn.datasets import load_iris, load_breast_cancer, load_digits\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def part1():\n",
    "\n",
    "    datasets = {\"iris\": load_iris(), \"breast cancer\":load_breast_cancer(), \"digits\": load_digits()}\n",
    "\n",
    "    print(\"-------------------------------------------\")\n",
    "\n",
    "    for key in datasets.keys():\n",
    "        dataset = datasets[key]\n",
    "\n",
    "        print(\"Training the\", key, \"dataset...\")\n",
    "\n",
    "        # Split the data in training and testing sets\n",
    "        print(\"Test = 40% - Train = 60%\")\n",
    "        X_train, X_test, y_train, y_test = train_test_split(dataset.data, dataset.target, test_size=0.4, random_state=0)\n",
    "\n",
    "        #Loop with different depths - 1 to 10\n",
    "        dataframe = pd.DataFrame(columns=['Depth', 'Avg # of Nodes', 'Accuracy'])\n",
    "        clf = tree.DecisionTreeClassifier()\n",
    "        for depth in range(1, 16):\n",
    "\n",
    "            clf = tree.DecisionTreeClassifier(max_depth=depth)\n",
    "            clf = clf.fit(X_train, y_train)\n",
    "            scores = cross_val_score(clf, dataset.data, dataset.target, cv=8)\n",
    "            #Unsure if the avg # of nodes is correct\n",
    "            dataframe.loc[depth] = [clf.get_depth(), clf.tree_.node_count/8, \"%0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2)]\n",
    "\n",
    "        print(dataframe)\n",
    "\n",
    "        # Select the best value of hyper-parameter and then use the entire training data to build a classifier. \n",
    "        best_value = clf.get_depth()\n",
    "        print(\"The best value for the depth hyper-parameter is\", best_value)\n",
    "\n",
    "        # Report the number of nodes and the accuracy of the classifier on the test set.\n",
    "        print(\"Testing the\", key, \"dataset with test data and with hyper-parameter...\")\n",
    "        clf = tree.DecisionTreeClassifier(max_depth=best_value)\n",
    "        clf = clf.fit(X_test, y_test)\n",
    "        scores = cross_val_score(clf, dataset.data, dataset.target, cv=8)\n",
    "        # Again not sure if number of nodes is correct\n",
    "        print(\"Number of nodes:\", clf.tree_.node_count/8)\n",
    "        print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "        print(\"---------------------------------------------------\")\n",
    "\n",
    "# Part 2\n",
    "\n",
    "def part2():\n",
    "    \n",
    "    \n",
    "    \n",
    "# Part 3\n",
    "\n",
    "def part3():\n",
    "    # Reading the file, latin encoding is used to avoid some errors\n",
    "    data = pd.read_csv('assignment1-2019-data.csv',encoding=('latin'),quoting=3)\n",
    "\n",
    "    # Creating the list of input and output variables.\n",
    "    inputVariables=list(data)\n",
    "    del inputVariables[4]\n",
    "    outputVariables=list(data)[4]\n",
    "    inputData=data[inputVariables]\n",
    "    \n",
    "    for column in inputData.columns:\n",
    "        if inputData[column].dtype==object:\n",
    "            dummyCols=pd.get_dummies(inputData[column])\n",
    "            inputData=inputData.join(dummyCols)\n",
    "            del inputData[column]\n",
    "    \n",
    "    model_1=LinearRegression()\n",
    "    model_1.fit(inputData, data[outputVariables])\n",
    "    coefficients=pd.DataFrame({'name':list(inputData),'value':model_1})\n",
    "    print(coefficients)\n",
    "    print(\"Mean squared error:\", np.mean((model_1.predict(inputData) - data[outputVariables]) ** 2))\n",
    "    print(\"R²:\", model_1.score(inputData, data[outputVariables]))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
