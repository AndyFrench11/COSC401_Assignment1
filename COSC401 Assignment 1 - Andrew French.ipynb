{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0]\n",
      "[[9.81802911e-01 1.81970751e-02 1.43580537e-08]\n",
      " [9.71729527e-01 2.82704429e-02 3.00353141e-08]]\n",
      "0.9733333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andyfrench/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Part 1\n",
    "# Andrew French - 11147452\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, train_test_split, cross_val_score\n",
    "from sklearn.datasets import load_iris, load_breast_cancer, load_digits\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "\n",
    "def part1():\n",
    "\n",
    "    datasets = {\"iris\": load_iris(), \"breast cancer\":load_breast_cancer(), \"digits\": load_digits()}\n",
    "\n",
    "    print(\"-------------------------------------------\")\n",
    "\n",
    "    for key in datasets.keys():\n",
    "        dataset = datasets[key]\n",
    "\n",
    "        print(\"Training the\", key, \"dataset...\")\n",
    "\n",
    "        # Split the data in training and testing sets\n",
    "        print(\"Test = 40% - Train = 60%\")\n",
    "        X_train, X_test, y_train, y_test = train_test_split(dataset.data, dataset.target, test_size=0.4, random_state=0)\n",
    "\n",
    "        #Loop with different depths - 1 to 10\n",
    "        dataframe = pd.DataFrame(columns=['Depth', 'Avg # of Nodes', 'Accuracy'])\n",
    "        clf = tree.DecisionTreeClassifier()\n",
    "        for depth in range(1, 16):\n",
    "\n",
    "            clf = tree.DecisionTreeClassifier(max_depth=depth)\n",
    "            clf = clf.fit(X_train, y_train)\n",
    "            scores = cross_val_score(clf, dataset.data, dataset.target, cv=8)\n",
    "            #Unsure if the avg # of nodes is correct\n",
    "            dataframe.loc[depth] = [clf.get_depth(), clf.tree_.node_count/8, \"%0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2)]\n",
    "\n",
    "        print(dataframe)\n",
    "\n",
    "        # Select the best value of hyper-parameter and then use the entire training data to build a classifier. \n",
    "        best_value = clf.get_depth()\n",
    "        print(\"The best value for the depth hyper-parameter is\", best_value)\n",
    "\n",
    "        # Report the number of nodes and the accuracy of the classifier on the test set.\n",
    "        print(\"Testing the\", key, \"dataset with test data and with hyper-parameter...\")\n",
    "        clf = tree.DecisionTreeClassifier(max_depth=best_value)\n",
    "        clf = clf.fit(X_test, y_test)\n",
    "        scores = cross_val_score(clf, dataset.data, dataset.target, cv=8)\n",
    "        # Again not sure if number of nodes is correct\n",
    "        print(\"Number of nodes:\", clf.tree_.node_count/8)\n",
    "        print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "        print(\"---------------------------------------------------\")\n",
    "\n",
    "# Part 2\n",
    "\n",
    "def part2():\n",
    "\n",
    "    X, y = load_iris(return_X_y=True)\n",
    "    clf = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial').fit(X, y)\n",
    "    print(clf.predict(X[:2, :]))\n",
    "\n",
    "    print(clf.predict_proba(X[:2, :]))\n",
    "\n",
    "    print(clf.score(X, y))\n",
    "    \n",
    "#     Construct the problem by defining a function (formula) that decides the\n",
    "#     class label of a point in R\n",
    "#     . This is the true f which is typically unknown\n",
    "#     but not here since you are defining the problem and generating the data.\n",
    "#     You must then generate some training and test data in R\n",
    "#     2×{P, N}, where\n",
    "#     P and N indicate the positive and negative class respectively. Visualise a\n",
    "#     sample of points.\n",
    "#     • Show how various tree sizes (from shallow to deep) perform with different\n",
    "#     training sizes. Iterate over a range tree depths and training data sizes and\n",
    "#     report the test accuracy in a table.\n",
    "#     • Provide a visualization of the actual and learned class boundaries (for a\n",
    "#     single tree). The visualisation must demonstrate the issue.\n",
    "#     • Very briefly (in a few sentences) discuss what would happen if the problem\n",
    "#     was R\n",
    "#     d with a large d.\n",
    "    \n",
    "    \n",
    "    \n",
    "# Part 3\n",
    "\n",
    "def part3():\n",
    "    # Reading the file, latin encoding is used to avoid some errors\n",
    "    data = pd.read_csv('assignment1-2019-data.csv',encoding=('latin'),quoting=3)\n",
    "\n",
    "    # Creating the list of input and output variables.\n",
    "    inputVariables=list(data)\n",
    "    del inputVariables[4]\n",
    "    outputVariables=list(data)[4]\n",
    "    inputData=data[inputVariables]\n",
    "    \n",
    "    for column in inputData.columns:\n",
    "        if inputData[column].dtype==object:\n",
    "            dummyCols=pd.get_dummies(inputData[column])\n",
    "            inputData=inputData.join(dummyCols)\n",
    "            del inputData[column]\n",
    "    \n",
    "    model_1=LinearRegression()\n",
    "    model_1.fit(inputData, data[outputVariables])\n",
    "    coefficients=pd.DataFrame({'name':list(inputData),'value':model_1})\n",
    "    print(\"Mean squared error:\", np.mean((model_1.predict(inputData) - data[outputVariables]) ** 2))\n",
    "    print(\"R²:\", model_1.score(inputData, data[outputVariables]))\n",
    "    \n",
    "#     Round the coefficients of the learned model to integers and write a casebased definition of the functions identified by the regression model(s).\n",
    "#     See http://scikit-learn.org/stable/modules/linear_model.html or if you are familiar\n",
    "#     with R see https://www.statsmodels.org/dev/example_formulas.html\n",
    "#     Each case must be a linear expression of the input variables (one expression\n",
    "#     per level of the categorical variable). For example:\n",
    "#     y =\n",
    "#     \n",
    "#     \n",
    "#     \n",
    "#     w1,1x1 + w1,2x2 + w1,3x3 + b1, c = l1\n",
    "#     w2,1x1 + w2,2x2 + w2,3x3 + b2, c = l2\n",
    "#     w3,1x1 + w3,2x2 + w3,3x3 + b3, c = l3\n",
    "#     where wi,j is the integer coefficient of the j-th numerical feature corresponding to the i-th level in the domain of the categorical feature; bi\n",
    "#     is\n",
    "#     the intercept in each case, and li\n",
    "#     is the i-th level in the domain of the\n",
    "#     categorical feature c.\n",
    "#     • Depending on the method you used for regression, described how a new\n",
    "#     (unseen) data point (an input vector of size 4) can be assigned a predicted\n",
    "#     value.\n",
    "\n",
    "#Current Running Part\n",
    "part2()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
